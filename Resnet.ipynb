{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we download a pre-trained Resnet 50-layer model on Imagenet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, urllib\n",
    "def download(url):\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    if not os.path.exists(filename):\n",
    "        urllib.urlretrieve(url, filename)\n",
    "def get_model(prefix, epoch):\n",
    "    download(prefix+'-symbol.json')\n",
    "    download(prefix+'-%04d.params' % (epoch,))\n",
    "\n",
    "get_model('http://data.dmlc.ml/mxnet/models/imagenet/resnet/200-layers/resnet-200', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialization\n",
    "\n",
    "We first load the model into memory with load_checkpoint. It returns the symbol (see symbol.ipynb) definition of the neural network, and parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "sym, arg_params, aux_params = mx.model.load_checkpoint('resnet-200', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create an executable module on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mod = mx.mod.Module(symbol=sym, context=mx.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ResNet is trained with RGB images of size 224 x 224. The training data is feed by the variable data. We bind the module with the input shape and specify that it is only for predicting. The number 1 added before the image shape (3x224x224) means that we will only predict one image each time. Next we set the loaded parameters. Now the module is ready to run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod.bind(for_training = False,\n",
    "         data_shapes=[('data', (1,3,224,224))])\n",
    "mod.set_params(arg_params, aux_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">', '<html><head>', '<title>404 Not Found</title>', '</head><body>', '<h1>Not Found</h1>', '<p>The requested URL /models/imagenet/resnet/synset1.txt was not found on this server.</p>', '<hr>', '<address>Apache/2.4.7 (Ubuntu) Server at data.mxnet.io Port 80</address>', '</body></html>']\n"
     ]
    }
   ],
   "source": [
    "download('http://data.mxnet.io/models/imagenet/resnet/synset1.txt')\n",
    "with open('synset1.txt') as f:\n",
    "    synsets = [l.rstrip() for l in f]\n",
    "print(synsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "#download('http://data.mxnet.io/data/val_1000.tar')\n",
    "tfile_flower = tarfile.open('flowers.tar.gz')\n",
    "tfile_flower.extractall()\n",
    "val_label = [0 for f in os.listdir('flowers')]\n",
    "\n",
    "\n",
    "tfile_bird = tarfile.open('birds.tar.gz')\n",
    "tfile_bird.extractall()\n",
    "val_label = [0 for f in os.listdir('birds')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rc(\"savefig\", dpi=100)\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define a function that reads one image each time and convert to a format can be used by the model. Here we use a naive way that resizes the original image into the desired shape, and change the data layout. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "def get_image(filename):\n",
    "    img = cv2.imread(filename)  # read image in b,g,r order\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)   # change to r,g,b order\n",
    "    img = cv2.resize(img, (224, 224))  # resize to 224*224 to fit model\n",
    "    img = np.swapaxes(img, 0, 2)\n",
    "    img = np.swapaxes(img, 1, 2)  # change to (channel, height, width)\n",
    "    img = img[np.newaxis, :]  # extend to (example, channel, heigth, width)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n",
      "101\n",
      "101\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir('flowers')\n",
    "flower_img=[]\n",
    "flower_img_rep=[]\n",
    "flower_lbl=[]\n",
    "i=0\n",
    "for file in files:\n",
    "    \n",
    "    img = get_image('flowers/'+file)\n",
    "    if i>100:\n",
    "        break\n",
    "    flower_img_rep.append(cv2.imread(file, cv2.COLOR_BGR2RGB))\n",
    "    flower_img.append(img)\n",
    "    flower_lbl.append('flower')\n",
    "    i=i+1\n",
    "files = os.listdir('birds')\n",
    "bird_img=[]\n",
    "bird_img_rep=[]\n",
    "bird_lbl=[]\n",
    "i=0\n",
    "for file in files:\n",
    "    img = get_image('birds/'+file)\n",
    "    if i>100:\n",
    "        break\n",
    "    bird_img_rep.append(cv2.imread(file, cv2.COLOR_BGR2RGB))\n",
    "    bird_img.append(img)\n",
    "    bird_lbl.append('bird')\n",
    "    i=i+1\n",
    "files = os.listdir('food')\n",
    "food_img=[]\n",
    "food_img_rep=[]\n",
    "food_lbl=[]\n",
    "i=0\n",
    "for file in files:\n",
    "    img = get_image('food/'+file)\n",
    "    if i>100:\n",
    "        break   \n",
    "    food_img_rep.append(cv2.imread(file, cv2.COLOR_BGR2RGB))\n",
    "    food_img.append(img)\n",
    "    food_lbl.append('food')\n",
    "    i=i+1\n",
    "print len(bird_img)\n",
    "print len(flower_img)\n",
    "print len(food_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "140\n",
      "210\n"
     ]
    }
   ],
   "source": [
    "train_img = []\n",
    "train_lbl = []\n",
    "test_img = []\n",
    "test_lbl = []\n",
    "train_img = flower_img[:len(flower_img)*7/10] \n",
    "train_lbl = flower_lbl[:len(flower_lbl)*7/10]\n",
    "test_img = flower_img[len(flower_img)*7/10:] \n",
    "test_lbl = flower_lbl[len(flower_lbl)*7/10:]  \n",
    "test_img_rep = flower_img_rep[len(flower_img)*7/10:]\n",
    "print len(train_lbl)\n",
    "train_img.extend(bird_img[:len(bird_img)*7/10]) \n",
    "train_lbl.extend(bird_lbl[:len(bird_lbl)*7/10])\n",
    "test_img.extend(bird_img[len(bird_img)*7/10:]) \n",
    "test_lbl.extend(bird_lbl[len(bird_lbl)*7/10:])  \n",
    "test_img_rep = bird_img_rep[len(bird_img)*7/10:]\n",
    "print len(train_lbl)\n",
    "train_img.extend(food_img[:len(bird_img)*7/10]) \n",
    "train_lbl.extend(food_lbl[:len(bird_lbl)*7/10])\n",
    "test_img.extend(food_img[len(bird_img)*7/10:]) \n",
    "test_lbl.extend(food_lbl[len(bird_lbl)*7/10:])  \n",
    "test_img_rep = food_img_rep[len(bird_img)*7/10:]\n",
    "print len(train_lbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we define a input data structure which is acceptable by mxnet. The field data is used for the input data, which is a list of NDArrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "Batch = namedtuple('Batch', ['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Features\n",
    "\n",
    "Sometime we want the internal outputs from a neural network rather than then final predicted probabilities. In this way, the neural network works as a feature extraction module to other applications.\n",
    "\n",
    "A loaded symbol in default only returns the last layer as output. But we can get all internal layers by get_internals, which returns a new symbol outputting all internal layers. The following codes print the last 10 layer names.\n",
    "\n",
    "We can also use mx.viz.plot_network(sym) to visually find the name of the layer we want to use. The name conventions of the output is the layer name with _output as the postfix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bn1_moving_var',\n",
       " 'bn1_output',\n",
       " 'relu1_output',\n",
       " 'pool1_output',\n",
       " 'flatten0_output',\n",
       " 'fc1_weight',\n",
       " 'fc1_bias',\n",
       " 'fc1_output',\n",
       " 'softmax_label']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_layers = sym.get_internals()\n",
    "all_layers.list_outputs()[-10:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often we want to use the output before the last fully connected layers, which may return semantic features of the raw images but not too fitting to the label yet. In the ResNet case, it is the flatten layer with name flatten0 before the last fullc layer. The following codes get the new symbol sym3 which use the flatten layer as the last output layer, and initialize a new module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_layers = sym.get_internals()\n",
    "sym3 = all_layers['flatten0_output']\n",
    "mod3 = mx.mod.Module(symbol=sym3, context=mx.cpu())\n",
    "mod3.bind(for_training=False, data_shapes=[('data', (1,3,224,224))])\n",
    "mod3.set_params(arg_params, aux_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "(210, 2048)\n"
     ]
    }
   ],
   "source": [
    "length = len(train_img)\n",
    "featuremap=[]\n",
    "for i in range(0,length):\n",
    "    img = train_img[i]\n",
    "    mod3.forward(Batch([mx.nd.array(img)]))\n",
    "    out = mod3.get_outputs()[0].asnumpy()\n",
    "    featuremap.append(out.flatten())\n",
    "    print i\n",
    "train_images = np.array(featuremap)\n",
    "print(train_images.shape)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Training MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 2048)\n",
      "210\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=10, learning_rate='constant',\n",
       "       learning_rate_init=0.01, max_iter=500, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "print train_images.shape\n",
    "print len(train_lbl)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10),solver='adam',learning_rate_init=0.01,max_iter=500)\n",
    "\n",
    "mlp.fit(train_images, train_lbl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing and calculating accuracy of the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n",
      "('flower', 'flower')\n",
      "('flower', 'flower')\n",
      "('flower', 'flower')\n",
      "('flower', 'flower')\n",
      "('flower', 'flower')\n",
      "('flower', 'flower')\n",
      "('flower', 'flower')\n",
      "('flower', 'flower')\n",
      "('flower', 'flower')\n",
      "('flower', 'flower')\n",
      "('flower', 'flower')\n",
      "('flower', 'flower')\n",
      "('flower', 'flower')\n",
      "('flower', 'flower')\n",
      "('flower', 'flower')\n",
      "('flower', 'flower')\n",
      "('flower', 'flower')\n",
      "('flower', 'flower')\n",
      "('flower', 'flower')\n",
      "('flower', 'flower')\n",
      "('flower', 'flower')\n",
      "('flower', 'flower')\n",
      "('flower', 'flower')\n",
      "('flower', 'flower')\n",
      "('flower', 'flower')\n",
      "('flower', 'flower')\n",
      "('flower', 'flower')\n",
      "('flower', 'flower')\n",
      "('flower', 'flower')\n",
      "('flower', 'flower')\n",
      "('flower', 'flower')\n",
      "('bird', 'bird')\n",
      "('bird', 'bird')\n",
      "('bird', 'bird')\n",
      "('bird', 'bird')\n",
      "('bird', 'bird')\n",
      "('bird', 'bird')\n",
      "('bird', 'bird')\n",
      "('bird', 'bird')\n",
      "('bird', 'bird')\n",
      "('bird', 'bird')\n",
      "('bird', 'bird')\n",
      "('bird', 'bird')\n",
      "('bird', 'bird')\n",
      "('bird', 'bird')\n",
      "('bird', 'bird')\n",
      "('bird', 'bird')\n",
      "('bird', 'bird')\n",
      "('bird', 'bird')\n",
      "('bird', 'bird')\n",
      "('bird', 'bird')\n",
      "('bird', 'bird')\n",
      "('bird', 'bird')\n",
      "('bird', 'bird')\n",
      "('bird', 'bird')\n",
      "('bird', 'bird')\n",
      "('bird', 'bird')\n",
      "('bird', 'bird')\n",
      "('bird', 'bird')\n",
      "('bird', 'bird')\n",
      "('bird', 'bird')\n",
      "('bird', 'bird')\n",
      "('food', 'food')\n",
      "('food', 'food')\n",
      "('food', 'food')\n",
      "('food', 'food')\n",
      "('food', 'food')\n",
      "('food', 'food')\n",
      "('food', 'food')\n",
      "('food', 'food')\n",
      "('food', 'food')\n",
      "('food', 'food')\n",
      "('food', 'food')\n",
      "('food', 'food')\n",
      "('food', 'food')\n",
      "('food', 'food')\n",
      "('food', 'food')\n",
      "('food', 'food')\n",
      "('food', 'food')\n",
      "('food', 'food')\n",
      "('food', 'food')\n",
      "('food', 'food')\n",
      "('food', 'food')\n",
      "('food', 'food')\n",
      "('food', 'food')\n",
      "('food', 'food')\n",
      "('food', 'food')\n",
      "('food', 'food')\n",
      "('food', 'food')\n",
      "('food', 'food')\n",
      "('food', 'food')\n",
      "('flower', 'food')\n",
      "('food', 'food')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.989247311827957"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predict_lbl = []\n",
    "print len(test_lbl)\n",
    "length = len(test_img)\n",
    "for i in range(0,length):\n",
    "    img = test_img[i]\n",
    "    mod3.forward(Batch([mx.nd.array(img)]))\n",
    "    out = mod3.get_outputs()[0].asnumpy()\n",
    "    predict_lbl.append(mlp.predict([out.flatten()])[0])\n",
    "    print(predict_lbl[i],test_lbl[i])\n",
    "    \n",
    "accuracy_score(test_lbl, predict_lbl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
